{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from pprint import pprint\n",
    "from easydict import EasyDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI = \"/home/home01/scrb/01_repos/CardiacMotion/mlruns/\"\n",
    "EXPERIMENT_NAME = \"Synthetic data\"\n",
    "EXPERIMENT_NAME = \"test\"\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_URI = mlflow.tracking.get_tracking_uri()\n",
    "EXPERIMENT_ID = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "PREFIX = f\"{MLFLOW_URI}/{EXPERIMENT_ID}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_yamls = [f\"{PREFIX}/{run}/meta.yaml\" for run in os.listdir(PREFIX) if os.path.exists(f\"{PREFIX}/{run}/meta.yaml\")]\n",
    "\n",
    "count = 0\n",
    "for meta_yaml_path in meta_yamls:\n",
    "    meta_yaml = yaml.safe_load(open(meta_yaml_path))    \n",
    "    if meta_yaml['experiment_id'] != EXPERIMENT_ID:\n",
    "        meta_yaml['experiment_id'] = EXPERIMENT_ID\n",
    "        count += 1\n",
    "        yaml.dump(meta_yaml, open(meta_yaml_path, \"wt\"))\n",
    "        \n",
    "if count != 0:\n",
    "    print(f\"{count} runs's experiments were fixed to match the experiment of the parent folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mlflow.search_runs(experiment_ids=[EXPERIMENT_ID])\n",
    "df = df[df[\"metrics.test_rec_ratio_to_time_mean\"] < 0.9]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select runs with $T=1$\n",
    "\n",
    "# row_index = (df[\"params.dataset_n_timeframes\"] == \"1\")\n",
    "# \n",
    "# # Select runs with performance better than random\n",
    "# row_index &= (df[\"metrics.test_rec_ratio_to_pop_mean\"] < 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns\n",
    "normalized_metrics = df.columns[df.columns.str.startswith(\"metrics.test_\") & df.columns.str.contains(\"ratio\")]\n",
    "\n",
    "dataset_params = df.columns[df.columns.str.startswith(\"params.dataset_\")].to_list()\n",
    "\n",
    "params = df.columns[df.columns.str.startswith(\"params.\")].to_list()\n",
    "\n",
    "arch_params = [\n",
    "    'params.n_channels_enc', \n",
    "    'params.n_channels_dec_c', \n",
    "    'params.n_channels_dec_s', \n",
    "    'params.latent_dim_c', \n",
    "    'params.latent_dim_s',\n",
    "    'params.z_aggr_function',\n",
    "    'params.reduction_factors',\n",
    "]\n",
    "\n",
    "# To not display columns that have the same value for all rows\n",
    "# https://stackoverflow.com/questions/57365283/how-to-show-columns-that-have-different-values-in-rows\n",
    "def diff_cols(df):\n",
    "    my_cols = []\n",
    "    for col in df.columns:\n",
    "        if df[col].nunique(dropna=False) > 1:\n",
    "            my_cols.append(col)\n",
    "    return df[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"run_id\"] + params + normalized_metrics.tolist()\n",
    "\n",
    "diff_cols(\n",
    "    df[columns].reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_runs = df.run_id.values\n",
    "run_w = widgets.Select(options=good_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @interact\n",
    "# def get_ckptpath(run=run_w):\n",
    "#     \n",
    "#     # chkpt_dir = f\"{MLFLOW_TRACKING_URI}/{EXPERIMENT_ID}/{RUNID}/\"\n",
    "#     \n",
    "#     REPO_DIR = \"/root/Rodrigo_repos/CardiacMotion\"\n",
    "#     global ckpt_path, model_weights    \n",
    "#     ckpt_path = glob.glob(f\"{REPO_DIR}/1/{run}/checkpoints/*ckpt\")    \n",
    "#     if len(ckpt_path) == 1:\n",
    "#       ckpt_path = ckpt_path[0]\n",
    "#     elif len(ckpt_path) == 0:\n",
    "#       ckpt_path = None\n",
    "#     \n",
    "#     model_weights = torch.load(ckpt_path)[\"state_dict\"]\n",
    "#     model_weights = EasyDict(model_weights)\n",
    "#     \n",
    "#     print(mlflow.get_run(run).data.metrics[\"test_rec_ratio_to_pop_mean\"])\n",
    "#     return ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params = 0\n",
    "\n",
    "for module_name, weights in model_weights.items():\n",
    "    module_name = module_name.replace(\"model.\", \"\")\n",
    "    n_params += np.prod(weights.shape)\n",
    "    # print(f'{module_name}: {weights.shape}')\n",
    "    \n",
    "n_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Get run IDs based on metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_w = widgets.Select(options=[\"6a4d73fb59f24d97b37764afdedd4185\"])\n",
    "run_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = f\"/home/home01/scrb/01_repos/CardiacMotion/mlruns/1//{run_w.value}/checkpoints\"\n",
    "ckpt_path = f\"{ckpt_dir}/{os.listdir(ckpt_dir)[0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_path = f\"/root/Rodrigo_repos/CardiacMotion/2/{run_w.value}/checkpoints/epoch=334-step=38524.ckpt\"\n",
    "model_weights = torch.load(ckpt_path)[\"state_dict\"]\n",
    "print(f\"Loaded weights from checkpoint:\\n {ckpt_path}\")\n",
    "model_weights = EasyDict(model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Initialize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle as pkl\n",
    "import os\n",
    "\n",
    "os.environ[\"HOME\"] = \"/root\"\n",
    "os.environ['CARDIAC_MOTION_REPO'] = os.environ[\"HOME\"] + \"/Rodrigo_repos/CardiacMotion\"\n",
    "os.chdir(os.environ['CARDIAC_MOTION_REPO'])\n",
    "\n",
    "sys.path.append(os.environ['CARDIAC_MOTION_REPO'])\n",
    "\n",
    "from main_autoencoder_cardiac import *\n",
    "from config.load_config import load_yaml_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### Synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helpers import get_coma_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_yaml_config(\"config_files/config_folded_c_and_s.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.SyntheticDataModules import SyntheticMeshesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.load_config import load_yaml_config\n",
    "config = load_yaml_config(\"config_files/config_folded_c_and_s.yaml\")\n",
    "config.dataset.parameters.N = 1280\n",
    "config.dataset.parameters.T = 20\n",
    "config.dataset.random_seed = 135\n",
    "\n",
    "mesh_ds = SyntheticMeshesDataset(config.dataset.parameters, config.dataset.preprocessing)\n",
    "mesh_dl = DataLoader(mesh_ds, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.network_architecture.latent_dim_c = 9\n",
    "config.network_architecture.latent_dim_s = 36\n",
    "\n",
    "POLYNOMIAL_DEGREE = 10\n",
    "DOWNSAMPLING = 2\n",
    "config.network_architecture.convolution.parameters.polynomial_degree = [POLYNOMIAL_DEGREE] * 4\n",
    "config.network_architecture.pooling.parameters.downsampling_factors = [DOWNSAMPLING] * 4\n",
    "\n",
    "coma_args = get_coma_args(config, mesh_dl.dataset)\n",
    "x = EasyDict(next(iter(mesh_dl)))\n",
    "mesh_template = mesh_ds.mesh_popu.template # mesh_dm.dataset.template_mesh\n",
    "\n",
    "from models.Model3D import Encoder3DMesh, Decoder3DMesh\n",
    "from models.Model4D import DECODER_C_ARGS, DECODER_S_ARGS, ENCODER_ARGS\n",
    "from models.Model4D import DecoderStyle, DecoderContent, DecoderTemporalSequence \n",
    "from models.Model4D import EncoderTemporalSequence, AutoencoderTemporalSequence\n",
    "from lightning.ComaLightningModule import CoMA_Lightning\n",
    "\n",
    "from models.lightning.EncoderLightningModule import TemporalEncoderLightning\n",
    "from models.TemporalAggregators import TemporalAggregator, FCN_Aggregator\n",
    "\n",
    "enc_config = EasyDict({k: v for k, v in coma_args.items() if k in ENCODER_ARGS})\n",
    "encoder = Encoder3DMesh(**enc_config)\n",
    "\n",
    "enc_config.latent_dim = config.network_architecture.latent_dim_c + config.network_architecture.latent_dim_s \n",
    "\n",
    "h = encoder.forward_conv_stack(x.s_t, preserve_graph_structure=False)\n",
    "\n",
    "NT = 20 # config.dataset.parameters.T\n",
    "    \n",
    "z_aggr = FCN_Aggregator(\n",
    "    features_in = NT*h.shape[-1],\n",
    "    features_out= enc_config.latent_dim\n",
    ")\n",
    "\n",
    "t_encoder = EncoderTemporalSequence(\n",
    "    encoder3d = encoder,\n",
    "    z_aggr_function=z_aggr\n",
    ")\n",
    "\n",
    "decoder_config_c = EasyDict({ k:v for k,v in coma_args.items() if k in DECODER_C_ARGS })\n",
    "decoder_config_s = EasyDict({ k:v for k,v in coma_args.items() if k in DECODER_S_ARGS })    \n",
    "decoder_content = DecoderContent(decoder_config_c)\n",
    "decoder_style = DecoderStyle(decoder_config_s, phase_embedding_method=\"exp_v1\")\n",
    "t_decoder = DecoderTemporalSequence(decoder_content, decoder_style)\n",
    "    \n",
    "t_ae = AutoencoderTemporalSequence(\n",
    "    encoder=t_encoder,\n",
    "    decoder=t_decoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_aliased = {k.replace(\"model.\", \"\"):v for k,v in model_weights.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ae.load_state_dict(model_weights_aliased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ae = t_ae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hat = []\n",
    "for i, batch in enumerate(mesh_dl):\n",
    "    # print(i)\n",
    "    x = batch[\"s_t\"].cuda()\n",
    "    z = t_ae(x)[0]['mu'].cpu()\n",
    "    z_hat.append(z)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hat = torch.concat(z_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_c_list = []\n",
    "z_s_list = []\n",
    "\n",
    "for i, batch in enumerate(mesh_dl):\n",
    "    z_c = batch['z_c']\n",
    "    z_s = batch['z_s']\n",
    "    z_c = torch.concat([z.unsqueeze(0) for z in z_c])\n",
    "    z_s = torch.concat([z.unsqueeze(0) for z in z_s])\n",
    "    z_c_list.append(z_c)\n",
    "    z_s_list.append(z_s)\n",
    "    \n",
    "z_c = torch.concat(z_c_list, axis=1).T\n",
    "z_s = torch.concat(z_s_list, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.concat([z_c, z_s], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def scatter_cca(component=widgets.IntSlider(min=0,max=44), which_plot=widgets.Select(options=[\"correlation\", \"weights\"])):\n",
    "    \n",
    "    X, Y = z.detach().numpy(), z_hat.detach().numpy()\n",
    "    Y = Y[:, component]\n",
    "    cca = CCA(n_components=1) \n",
    "    real_z, pred_z = cca.fit_transform(X, Y)\n",
    "    \n",
    "    if which_plot == \"correlation\":\n",
    "      plt.scatter(real_z, pred_z);\n",
    "      plt.xlabel(\"real z\")\n",
    "      plt.ylabel(\"best linear combination of predicted z's\")\n",
    "    \n",
    "    elif which_plot == \"weights\":\n",
    "      plt.plot(cca.x_weights_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "kk[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "cca.fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hat = torch.concat(z_hat).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "#### Cardiac dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_autoencoder_cardiac import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "POLYNOMIAL_DEGREE = 6\n",
    "DOWNSAMPLING = 2\n",
    "\n",
    "config = load_yaml_config(\"config_files/config_folded_c_and_s.yaml\")\n",
    "config.network_architecture.convolution.parameters.polynomial_degree = [POLYNOMIAL_DEGREE] * 4\n",
    "config.network_architecture.pooling.parameters.downsampling_factors = [DOWNSAMPLING] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = EasyDict(\n",
    "        pkl.load(open(\"utils/VTKHelpers/data/faces_and_downsampling_mtx_frac_0.1_LV.pkl\", \"rb\"))\n",
    ").new_faces\n",
    "\n",
    "template = EasyDict({\n",
    "  \"v\": np.load(f\"{os.environ['CARDIAC_MOTION_REPO']}/data/LV_shape_mean_across_timepoints.npy\"),\n",
    "  \"f\": faces\n",
    "})\n",
    "\n",
    "\n",
    "cardiac_dataset = CardiacMeshPopulationDataset(\n",
    "    root_path=\"data/cardio/Results\", \n",
    "    procrustes_transforms=\"utils/VTKHelpers/data/procrustes_transforms_FHM_35k.pkl\",\n",
    "    faces=faces,\n",
    "    template_mesh=template,        \n",
    ")\n",
    "\n",
    "mesh_dm = CardiacMeshPopulationDM(cardiac_dataset, batch_size=32)\n",
    "\n",
    "# datamodule = get_datamodule(config.dataset, batch_size=config.batch_size)\n",
    "\n",
    "config.network_architecture.latent_dim_c = 8 \n",
    "config.network_architecture.latent_dim_s = 16\n",
    "\n",
    "mesh_dm.setup()\n",
    "x = EasyDict(next(iter(mesh_dm.train_dataloader())))\n",
    "\n",
    "mesh_template = mesh_dm.dataset.template_mesh\n",
    "coma_args = get_coma_args(config)\n",
    "coma_matrices = get_coma_matrices(config, mesh_template)\n",
    "coma_args.update(coma_matrices)\n",
    "\n",
    "from models.Model3D import Encoder3DMesh, Decoder3DMesh\n",
    "from models.Model4D import DECODER_C_ARGS, DECODER_S_ARGS, ENCODER_ARGS\n",
    "from models.Model4D import DecoderStyle, DecoderContent, DecoderTemporalSequence \n",
    "from models.Model4D import EncoderTemporalSequence, AutoencoderTemporalSequence\n",
    "from lightning.ComaLightningModule import CoMA_Lightning\n",
    "\n",
    "from models.lightning.EncoderLightningModule import TemporalEncoderLightning\n",
    "from models.TemporalAggregators import TemporalAggregator, FCN_Aggregator\n",
    "\n",
    "enc_config = EasyDict({k: v for k, v in coma_args.items() if k in ENCODER_ARGS})\n",
    "encoder = Encoder3DMesh(**enc_config)\n",
    "\n",
    "enc_config.latent_dim = config.network_architecture.latent_dim_c + config.network_architecture.latent_dim_s \n",
    "\n",
    "h = encoder.forward_conv_stack(x.s_t, preserve_graph_structure=False)\n",
    "\n",
    "NT = 50 # config.dataset.parameters.T\n",
    "    \n",
    "z_aggr = FCN_Aggregator(\n",
    "    features_in = NT*h.shape[-1],\n",
    "    features_out= enc_config.latent_dim\n",
    ")\n",
    "\n",
    "t_encoder = EncoderTemporalSequence(\n",
    "    encoder3d = encoder,\n",
    "    z_aggr_function=z_aggr\n",
    ")\n",
    "\n",
    "decoder_config_c = EasyDict({ k:v for k,v in coma_args.items() if k in DECODER_C_ARGS })\n",
    "decoder_config_s = EasyDict({ k:v for k,v in coma_args.items() if k in DECODER_S_ARGS })    \n",
    "decoder_content = DecoderContent(decoder_config_c)\n",
    "decoder_style = DecoderStyle(decoder_config_s, phase_embedding_method=\"exp_v1\")\n",
    "t_decoder = DecoderTemporalSequence(decoder_content, decoder_style)\n",
    "    \n",
    "t_ae = AutoencoderTemporalSequence(\n",
    "    encoder=t_encoder,\n",
    "    decoder=t_decoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = EasyDict({k.replace(\"model.\", \"\"): v for k, v in model_weights.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ae.load_state_dict(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_module = CoMA_Lightning(\n",
    "    model=t_ae, \n",
    "    loss_params=config.loss, \n",
    "    optimizer_params=config.optimizer,\n",
    "    additional_params=config,\n",
    "    mesh_template=mesh_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "### Load input meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(mesh_dm.val_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = t_ae(x[\"s_t\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "### Generate animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t, s_hat_t = x[\"s_t\"], output[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subj_idx_w = widgets.IntSlider(min=1, max=len(cardiac_dataset))\n",
    "\n",
    "def generate_gif(mesh4D, faces, filename, camera_position='xy', show_edges=False, **kwargs):\n",
    "        \n",
    "        '''\n",
    "        Produces a gif file representing the motion of the input mesh.\n",
    "        \n",
    "        params:\n",
    "          ::mesh4D:: a sequence of Trimesh mesh objects.\n",
    "          ::faces:: array of F x 3 containing the indices of the mesh's triangular faces.\n",
    "          ::filename:: the name of the output gif file.\n",
    "          ::camera_position:: camera position for pyvista plotter (check relevant docs)\n",
    "          \n",
    "        return:\n",
    "          None, only produces the gif file.\n",
    "        '''\n",
    "\n",
    "        import pyvista as pv\n",
    "        \n",
    "        connectivity = np.c_[np.ones(faces.shape[0]) * 3, faces].astype(int)\n",
    "                \n",
    "        pv.set_plot_theme(\"document\")\n",
    "        os.makedirs(os.path.dirname(\"./\"+filename) , exist_ok=True)\n",
    "        \n",
    "        # plotter = pv.Plotter(shape=(1, len(camera_positions)), notebook=False, off_screen=True)\n",
    "        pv.start_xvfb()\n",
    "        plotter = pv.Plotter(notebook=False, off_screen=True)\n",
    "            \n",
    "        # Open a gif\n",
    "        plotter.open_gif(filename)\n",
    "\n",
    "        try:\n",
    "            # if mesh3D is torch.Tensor, this your should run OK\n",
    "            mesh4D = mesh4D.cpu().numpy()[0].astype(\"float32\")\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "        kk = pv.PolyData(mesh4D[0], connectivity)\n",
    "        # plotter.add_mesh(kk, smooth_shading=True, opacity=0.5 )#, show_edges=True)\n",
    "        plotter.add_mesh(kk, show_edges=show_edges, opacity=0.5, color=\"red\") \n",
    "        \n",
    "        for t, _ in tqdm(enumerate(mesh4D)):\n",
    "            # print(t)\n",
    "            kk = pv.PolyData(mesh4D[t], connectivity)\n",
    "            plotter.camera_position = camera_position\n",
    "            plotter.update_coordinates(kk.points, render=False)\n",
    "            plotter.render()             \n",
    "            plotter.write_frame()\n",
    "        \n",
    "        plotter.close()\n",
    "        \n",
    "        return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "def merge_gifs_horizontally(gif_file1, gif_file2, output_file):\n",
    "    # Create reader object for the gif\n",
    "    gif1 = imageio.get_reader(gif_file1)\n",
    "    gif2 = imageio.get_reader(gif_file2)\n",
    "\n",
    "    # Create writer object\n",
    "    new_gif = imageio.get_writer(output_file)\n",
    "\n",
    "    for frame_number in range(gif1.get_length()):\n",
    "        img1 = gif1.get_next_data()\n",
    "        img2 = gif2.get_next_data()\n",
    "        # here is the magic\n",
    "        new_image = np.hstack((img1, img2))\n",
    "        new_gif.append_data(new_image)\n",
    "\n",
    "    gif1.close()\n",
    "    gif2.close()\n",
    "    new_gif.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "### Generate gif's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_ids = list(range(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj_id in subj_ids:\n",
    "        \n",
    "    mesh4D = s_hat_t.detach().cpu().numpy().astype(\"float32\")[subj_id]    \n",
    "    for camera in [\"xz\", \"xy\", \"yz\"]:    \n",
    "        gifpath = generate_gif(\n",
    "            mesh4D,\n",
    "            faces, \n",
    "            camera_position=camera,\n",
    "            filename=f\"id{subj_id}_reconstruction_{camera}.gif\"\n",
    "        )\n",
    "        \n",
    "       #b64 = base64.b64encode(\n",
    "       #  open(gifpath,'rb').read()\n",
    "       #).decode('ascii')\n",
    "        \n",
    "                \n",
    "    mesh4D = s_t.detach().cpu().numpy().astype(\"float32\")[subj_id]        \n",
    "    for camera in [\"xz\", \"xy\", \"yz\"]:    \n",
    "        gifpath = generate_gif(\n",
    "            mesh4D,\n",
    "            faces, \n",
    "            camera_position=camera,\n",
    "            filename=f\"id{subj_id}_original_{camera}.gif\", \n",
    "        )\n",
    "    \n",
    "        #b64 = base64.b64encode(\n",
    "        #    open(gifpath,'rb').read()\n",
    "        #).decode('ascii')\n",
    "    \n",
    "    for camera in [\"xz\", \"xy\", \"yz\"]: \n",
    "        \n",
    "        merge_gifs_horizontally(\n",
    "            f\"id{subj_id}_original_{camera}.gif\", \n",
    "            f\"id{subj_id}_reconstruction_{camera}.gif\", \n",
    "            f\"id{subj_id}_{camera}.gif\"\n",
    "        )\n",
    "        \n",
    "        os.remove(f\"id{subj_id}_original_{camera}.gif\")\n",
    "        os.remove(f\"id{subj_id}_reconstruction_{camera}.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_gif(subj_id=widgets.IntSlider(min=0,max=63)):\n",
    "    \n",
    "    from IPython.display import HTML\n",
    "    import base64\n",
    "   \n",
    "    \n",
    "    \n",
    "    display(HTML(f'<img src=\"data:image/gif;base64,{b64}\" />'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_id = \"15\"\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
