{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc17f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c3fec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.Model3D import Encoder3DMesh, Decoder3DMesh\n",
    "# from .PhaseModule import PhaseTensor\n",
    "# from .TemporalAggregators import Mean_Aggregator, DFT_Aggregator, FCN_Aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76863f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "from models.layers import ChebConv_Coma, Pool\n",
    "from typing import Sequence, Union, List\n",
    "from copy import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import ModuleList, ModuleDict\n",
    "from torch.fft import rfft\n",
    "\n",
    "from data.SyntheticDataModules import SyntheticMeshesDataset, SyntheticMeshesDM\n",
    "\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "from typing import Sequence, Union, List\n",
    "\n",
    "from IPython import embed # left there for debugging if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae607f3c",
   "metadata": {},
   "source": [
    "____\n",
    "## 3D models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2d9765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Implement common parent class for encoder and decoder (GraphConvStack?), to capture common behaviour.\n",
    "\n",
    "################# FULL AUTOENCODER #################\n",
    "\n",
    "class Autoencoder3DMesh(nn.Module):\n",
    "\n",
    "    def __init__(self, enc_config, dec_config):\n",
    "\n",
    "        super(Autoencoder3DMesh, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder3DMesh(**enc_config)\n",
    "        self.decoder = Decoder3DMesh(**dec_config)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        mu, logvar = self.encoder(x)\n",
    "        # Add sampling if is_variational == True and it's in training mode\n",
    "        x_hat = self.decoder(mu)\n",
    "        return x_hat\n",
    "\n",
    "################# ENCODER #################\n",
    "\n",
    "ENCODER_ARGS = [\n",
    "    \"num_features\",\n",
    "    \"n_layers\",\n",
    "    \"n_nodes\",\n",
    "    \"num_conv_filters_enc\",\n",
    "    \"cheb_polynomial_order\",\n",
    "    \"latent_dim_content\",\n",
    "    \"template\",\n",
    "    \"is_variational\",\n",
    "    \"phase_input\",\n",
    "    \"downsample_matrices\",\n",
    "    \"adjacency_matrices\",\n",
    "    \"activation_layers\"\n",
    "]\n",
    "\n",
    "class Encoder3DMesh(nn.Module):\n",
    "\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "        phase_input: bool,\n",
    "        num_conv_filters_enc: Sequence[int],\n",
    "        num_features: int,\n",
    "        cheb_polynomial_order: int,\n",
    "        n_layers: int,\n",
    "        n_nodes: int,\n",
    "        is_variational: bool,\n",
    "        latent_dim: int,\n",
    "        template,\n",
    "        adjacency_matrices: List[torch.Tensor],\n",
    "        downsample_matrices: List[torch.Tensor],\n",
    "        activation_layers=\"ReLU\"):\n",
    "\n",
    "        super(Encoder3DMesh, self).__init__()\n",
    "\n",
    "        self.n_nodes = n_nodes\n",
    "        self.phase_input = phase_input\n",
    "        self.filters_enc = copy(num_conv_filters_enc)\n",
    "        self.filters_enc.insert(0, num_features)\n",
    "        self.K = cheb_polynomial_order\n",
    "\n",
    "        self.matrices = {}\n",
    "        A_edge_index, A_norm = self._build_adj_matrix(adjacency_matrices)\n",
    "\n",
    "        self.matrices[\"A_edge_index\"] = A_edge_index\n",
    "        self.matrices[\"A_norm\"] = A_norm\n",
    "        self.matrices[\"downsample\"] = downsample_matrices\n",
    "                \n",
    "        self._n_features_before_z = self.matrices[\"downsample\"][-1].shape[0] * self.filters_enc[-1]\n",
    "        self._is_variational = is_variational\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.activation_layers = [activation_layers] * n_layers if isinstance(activation_layers, str) else activation_layers\n",
    "        self.layers = self._build_encoder()\n",
    "\n",
    "        # Fully connected layers connecting the last pooling layer and the latent space layer.\n",
    "        self.enc_lin_mu = torch.nn.Linear(self._n_features_before_z, self.latent_dim)\n",
    "\n",
    "        if self._is_variational:\n",
    "            self.enc_lin_var = torch.nn.Linear(self._n_features_before_z, self.latent_dim)\n",
    "\n",
    "    def _build_encoder(self):\n",
    "\n",
    "        cheb_conv_layers = self._build_cheb_conv_layers(self.filters_enc, self.K)\n",
    "        pool_layers = self._build_pool_layers(self.matrices[\"downsample\"])\n",
    "        activation_layers = self._build_activation_layers(self.activation_layers)\n",
    "\n",
    "        encoder = ModuleDict()\n",
    "\n",
    "        for i in range(len(cheb_conv_layers)):\n",
    "            layer = f\"layer_{i}\"\n",
    "            encoder[layer] = ModuleDict()            \n",
    "            encoder[layer][\"graph_conv\"] = cheb_conv_layers[i]\n",
    "            encoder[layer][\"pool\"] = pool_layers[i]\n",
    "            encoder[layer][\"activation_function\"] = activation_layers[i]\n",
    "\n",
    "        return encoder\n",
    "\n",
    "    def _build_pool_layers(self, downsample_matrices:Sequence[np.array]):\n",
    "\n",
    "        '''\n",
    "        downsample_matrices: list of matrices binary matrices\n",
    "        '''\n",
    "\n",
    "        pool_layers = ModuleList()\n",
    "        for i in range(len(downsample_matrices)):\n",
    "            pool_layers.append(Pool())\n",
    "        return pool_layers\n",
    "\n",
    "\n",
    "    def _build_activation_layers(self, activation_type:Union[str, Sequence[str]]):\n",
    "\n",
    "        '''\n",
    "        activation_type: string or list of strings containing the name of a valid activation function from torch.functional\n",
    "        '''\n",
    "\n",
    "        activation_layers = ModuleList()\n",
    "\n",
    "        for i in range(len(activation_type)):\n",
    "            activ_fun = getattr(torch.nn.modules.activation, activation_type[i])()\n",
    "            activation_layers.append(activ_fun)\n",
    "\n",
    "        return activation_layers\n",
    "\n",
    "\n",
    "    def _build_cheb_conv_layers(self, n_filters, K):\n",
    "        # Chebyshev convolutions (encoder)\n",
    "\n",
    "        #TOFIX: this should be specified in the docs.\n",
    "        if self.phase_input:\n",
    "            n_filters[0] = 2 * n_filters[0]\n",
    "\n",
    "        cheb_enc = torch.nn.ModuleList([ChebConv_Coma(n_filters[0], n_filters[1], K[0])])\n",
    "        cheb_enc.extend([\n",
    "            ChebConv_Coma(\n",
    "                n_filters[i],\n",
    "                n_filters[i+1],\n",
    "                K[i]\n",
    "            ) for i in range(1, len(n_filters)-1)\n",
    "        ])\n",
    "        return cheb_enc\n",
    "\n",
    "\n",
    "    def _build_adj_matrix(self, adjacency_matrices):\n",
    "        adj_edge_index, adj_norm = zip(*[\n",
    "            ChebConv_Coma.norm(adjacency_matrices[i]._indices(), self.n_nodes[i])\n",
    "            for i in range(len(self.n_nodes))\n",
    "        ])\n",
    "        return list(adj_edge_index), list(adj_norm)\n",
    "\n",
    "    \n",
    "    def concatenate_graph_features(self, x):\n",
    "        embed()\n",
    "        x = x.reshape(x.shape[0], self._n_features_before_z)\n",
    "        return x\n",
    "\n",
    "\n",
    "    # perform a forward pass only through the convolutional stack (not the FCN layer)\n",
    "    def forward_conv_stack(self, x, preserve_graph_structure=True):\n",
    "        \n",
    "        # a \"layer\" here is: a graph convolution + pooling operation + activation function\n",
    "        for i, layer in enumerate(self.layers): \n",
    "            \n",
    "            if self.matrices[\"downsample\"][i].device != x.device:\n",
    "                self.matrices[\"downsample\"][i] = self.matrices[\"upsample\"][i].to(x.device)\n",
    "            if self.matrices[\"A_edge_index\"][i].device != x.device:\n",
    "                self.matrices[\"A_edge_index\"][i] = self.matrices[\"A_edge_index\"][i].to(x.device)\n",
    "            if self.matrices[\"A_norm\"][i].device != x.device:\n",
    "                self.matrices[\"A_norm\"][i] = self.matrices[\"A_norm\"][i].to(x.device)\n",
    "  \n",
    "            x = self.layers[layer][\"graph_conv\"](x, self.matrices[\"A_edge_index\"][i], self.matrices[\"A_norm\"][i])\n",
    "            try:\n",
    "                x = self.layers[layer][\"pool\"](x, self.matrices[\"downsample\"][i])\n",
    "            except:\n",
    "                embed()\n",
    "            x = self.layers[layer][\"activation_function\"](x)\n",
    "        \n",
    "        if not preserve_graph_structure:\n",
    "            x = self.concatenate_graph_features(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.forward_conv_stack(x)       \n",
    "        mu = self.enc_lin_mu(x)\n",
    "        log_var = self.enc_lin_var(x) if self._is_variational else None        \n",
    "        return {\"mu\": mu, \"log_var\": log_var}\n",
    "\n",
    "    \n",
    "################# DECODER #################\n",
    "\n",
    "DECODER_ARGS = [\n",
    "    \"num_features\",\n",
    "    \"n_layers\",\n",
    "    \"n_nodes\",\n",
    "    \"num_conv_filters_dec\",\n",
    "    \"cheb_polynomial_order\",\n",
    "    \"latent_dim_content\",\n",
    "    \"is_variational\",\n",
    "    \"upsample_matrices\",\n",
    "    \"adjacency_matrices\",\n",
    "    \"activation_layers\",\n",
    "    \"template\"\n",
    "]\n",
    "\n",
    "class Decoder3DMesh(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "        num_features: int,\n",
    "        n_layers: int,\n",
    "        n_nodes: int,\n",
    "        num_conv_filters_dec: Sequence[int],\n",
    "        cheb_polynomial_order: int,\n",
    "        latent_dim: int,\n",
    "        is_variational: bool,\n",
    "        template,\n",
    "        upsample_matrices: List[torch.Tensor],\n",
    "        adjacency_matrices: List[torch.Tensor],\n",
    "        activation_layers=\"ReLU\"):\n",
    "\n",
    "        super(Decoder3DMesh, self).__init__()\n",
    "\n",
    "        self.n_nodes = n_nodes\n",
    "        self.filters_dec = copy(num_conv_filters_dec)\n",
    "        self.filters_dec.insert(0, num_features)\n",
    "        self.filters_dec = list(reversed(self.filters_dec))\n",
    "\n",
    "        self.K = cheb_polynomial_order\n",
    "\n",
    "        self.matrices = {}\n",
    "        A_edge_index, A_norm = self._build_adj_matrix(adjacency_matrices)\n",
    "        self.matrices[\"A_edge_index\"] = list(reversed(A_edge_index))\n",
    "        self.matrices[\"A_norm\"] = list(reversed(A_norm))\n",
    "        self.matrices[\"upsample\"] = list(reversed(upsample_matrices))\n",
    "\n",
    "        self._n_features_before_z = self.matrices[\"upsample\"][0].shape[1] * self.filters_dec[0]\n",
    "\n",
    "        self._is_variational = is_variational\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.activation_layers = [activation_layers] * n_layers if isinstance(activation_layers, str) else activation_layers\n",
    "\n",
    "        # Fully connected layer connecting the latent space layer with the first upsampling layer.\n",
    "        self.dec_lin = torch.nn.Linear(self.latent_dim, self._n_features_before_z)\n",
    "\n",
    "        self.layers = self._build_decoder()\n",
    "\n",
    "\n",
    "    def _build_decoder(self):\n",
    "\n",
    "        cheb_conv_layers = self._build_cheb_conv_layers(self.filters_dec, self.K)\n",
    "        pool_layers = self._build_pool_layers(self.matrices[\"upsample\"])\n",
    "        activation_layers = self._build_activation_layers(self.activation_layers)\n",
    "\n",
    "        decoder = ModuleDict()\n",
    "\n",
    "        for i in range(len(cheb_conv_layers)):\n",
    "            layer = f\"layer_{i}\"\n",
    "            decoder[layer] = ModuleDict()\n",
    "            decoder[layer][\"activation_function\"] = activation_layers[i]\n",
    "            decoder[layer][\"pool\"] = pool_layers[i]\n",
    "            decoder[layer][\"graph_conv\"] = cheb_conv_layers[i]\n",
    "\n",
    "        return decoder\n",
    "\n",
    "\n",
    "    def _build_pool_layers(self, upsample_matrices:Sequence[np.array]):\n",
    "\n",
    "        '''\n",
    "        downsample_matrices: list of matrices binary matrices\n",
    "        '''\n",
    "\n",
    "        pool_layers = ModuleList()\n",
    "        for i in range(len(upsample_matrices)):\n",
    "            pool_layers.append(Pool())\n",
    "        return pool_layers\n",
    "\n",
    "\n",
    "    def _build_activation_layers(self, activation_type:Union[str, Sequence[str]]):\n",
    "\n",
    "        '''\n",
    "        activation_type: string or list of strings containing the name of a valid activation function from torch.functional\n",
    "        '''\n",
    "\n",
    "        activation_layers = ModuleList()\n",
    "\n",
    "        for i in range(len(activation_type)):\n",
    "            activ_fun = getattr(torch.nn.modules.activation, activation_type[i])()\n",
    "            activation_layers.append(activ_fun)\n",
    "\n",
    "        return activation_layers\n",
    "\n",
    "\n",
    "    def _build_cheb_conv_layers(self, n_filters, K):\n",
    "        # Chebyshev convolutions (decoder)\n",
    "        cheb_dec = torch.nn.ModuleList([ChebConv_Coma(n_filters[0], n_filters[1], K[0])])\n",
    "        for i in range(1, len(n_filters)-1):\n",
    "            conv_layer = ChebConv_Coma(n_filters[i], n_filters[i+1], K[i])\n",
    "            cheb_dec.extend([conv_layer])\n",
    "\n",
    "        cheb_dec[-1].bias = None  # No bias for last convolution layer\n",
    "        return cheb_dec\n",
    "\n",
    "\n",
    "    def _build_adj_matrix(self, adjacency_matrices):\n",
    "        adj_edge_index, adj_norm = zip(*[\n",
    "            ChebConv_Coma.norm(adjacency_matrices[i]._indices(), self.n_nodes[i])\n",
    "            for i in range(len(self.n_nodes))\n",
    "        ])\n",
    "        return list(adj_edge_index), list(adj_norm)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.dec_lin(x)\n",
    "        batch_size = x.shape[0] if x.dim() == 2 else 1\n",
    "        x = x.reshape(batch_size, -1, self.layers[\"layer_0\"][\"graph_conv\"].in_channels)\n",
    "\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            \n",
    "            if self.matrices[\"upsample\"][i].device != x.device:\n",
    "                self.matrices[\"upsample\"][i] = self.matrices[\"upsample\"][i].to(x.device)\n",
    "            if self.matrices[\"A_edge_index\"][i].device != x.device:\n",
    "                self.matrices[\"A_edge_index\"][i] = self.matrices[\"A_edge_index\"][i].to(x.device)\n",
    "            if self.matrices[\"A_norm\"][i].device != x.device:\n",
    "                self.matrices[\"A_norm\"][i] = self.matrices[\"A_norm\"][i].to(x.device)\n",
    "\n",
    "            x = self.layers[layer][\"activation_function\"](x)\n",
    "            x = self.layers[layer][\"pool\"](x, self.matrices[\"upsample\"][i])\n",
    "            x = self.layers[layer][\"graph_conv\"](x, self.matrices[\"A_edge_index\"][i], self.matrices[\"A_norm\"][i])\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e60a325",
   "metadata": {},
   "source": [
    "## 4D models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72c77a5",
   "metadata": {},
   "source": [
    "### Phase module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42863c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseTensor(nn.Module):\n",
    "\n",
    "    def __init__(self, version=\"version_1\"):\n",
    "\n",
    "        super(PhaseTensor, self).__init__()\n",
    "        self.version = version\n",
    "\n",
    "    def phase_tensor(self, x):\n",
    "        '''\n",
    "        params:\n",
    "          z: a batched vector (N x T x M)\n",
    "\n",
    "        returns:\n",
    "          a phase-aware vector (N x T x 2M)\n",
    "        '''\n",
    "\n",
    "        if self.version == \"version_1\":\n",
    "\n",
    "            sen_t = []; cos_t = []\n",
    "            n_timeframes, rank = x.shape[1], x.dim()\n",
    "\n",
    "            for i in range(n_timeframes):\n",
    "                phase = 2 * np.pi * i / n_timeframes\n",
    "                sen_t.append(np.sin(phase))\n",
    "                cos_t.append(np.cos(phase))\n",
    "\n",
    "            dims_to_expand = list(range(rank))\n",
    "            dims_to_expand.remove(1)  # don't expand along the \"time\" dimension\n",
    "            dims_to_expand = tuple(dims_to_expand)\n",
    "\n",
    "            sen_t = np.array(sen_t); cos_t = np.array(cos_t)\n",
    "            sen_t = np.expand_dims(sen_t, axis=dims_to_expand)\n",
    "            cos_t = np.expand_dims(cos_t, axis=dims_to_expand)\n",
    "            sen_t = torch.Tensor(sen_t); cos_t = torch.Tensor(cos_t)\n",
    "            sen_t = sen_t.type_as(x); cos_t = cos_t.type_as(x)\n",
    "\n",
    "            phased_x = torch.cat((sen_t * x, cos_t * x), dim=-1)\n",
    "            phased_x.type_as(x)\n",
    "\n",
    "        elif self.version == \"version_2\":\n",
    "\n",
    "            phased_x = x.type(torch.complex64)\n",
    "            n_timeframes = x.shape[1]\n",
    "\n",
    "            for t in range(n_timeframes):\n",
    "                phase = 2 * np.pi * t / n_timeframes * torch.ones_like(x[:, t, ...])\n",
    "                phase = torch.FloatTensor(phase)\n",
    "                phase = phase.type_as(x)  # to(x.device)\n",
    "\n",
    "                # torch.polar(x, phase) returns x * exp(i * phase), i.e. x as a phasor\n",
    "                phased_x[:, t, ...] = torch.polar(x[:, t, ...], phase)\n",
    "\n",
    "            # concatenate sin and cosine along last dimension\n",
    "            phased_x = torch.cat((phased_x.real, phased_x.imag), dim=-1)\n",
    "\n",
    "        return phased_x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.phase_tensor(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2649cd",
   "metadata": {},
   "source": [
    "### Temporal Aggregators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a454aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mean_Aggregator(nn.Module):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.Tensor.mean(x, axis=1)\n",
    "\n",
    "\n",
    "class FCN_Aggregator(nn.Module):\n",
    "\n",
    "    def __init__(self, features_in, features_out):\n",
    "        super(FCN_Aggregator, self).__init__()\n",
    "        self.fcn = torch.nn.Linear(features_in, features_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], x.shape[1] * x.shape[2])\n",
    "        return self.fcn(x)\n",
    "\n",
    "\n",
    "class DFT_Aggregator(nn.Module):\n",
    "\n",
    "    '''\n",
    "      x [N, T, ..., F] -> [N, ..., n_comps * F]\n",
    "    '''\n",
    "\n",
    "    def __init__(self, features_in, features_out):\n",
    "        super(DFT_Aggregator, self).__init__()\n",
    "        self.fcn = torch.nn.Linear(features_in, features_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = rfft(x, dim=1)\n",
    "        # Concatenate features in the frequency domain\n",
    "        x = x.reshape(x.shape[0], x.shape[1] * x.shape[2])\n",
    "        x = torch.cat((x.real, x.imag), dim=-1)\n",
    "        x = self.fcn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade31aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_DIMENSION = 0\n",
    "TIME_DIMENSION = 1\n",
    "NODE_DIMENSION = 2\n",
    "FEATURE_DIMENSION = 3\n",
    "\n",
    "COMMON_ARGS = [\n",
    "    \"num_features\",\n",
    "    \"n_layers\",\n",
    "    \"n_nodes\",\n",
    "    \"cheb_polynomial_order\",\n",
    "    \"is_variational\",\n",
    "    \"adjacency_matrices\",\n",
    "    \"activation_layers\",\n",
    "    \"template\",\n",
    "]\n",
    "\n",
    "ENCODER_ARGS = copy(COMMON_ARGS)\n",
    "ENCODER_ARGS.extend([\n",
    "  \"phase_input\",\n",
    "  \"downsample_matrices\",\n",
    "  \"num_conv_filters_enc\",\n",
    "  \"latent_dim_content\",\n",
    "  \"latent_dim_style\"\n",
    "])\n",
    "\n",
    "DECODER_C_ARGS = copy(COMMON_ARGS)\n",
    "DECODER_C_ARGS.extend([\n",
    "  \"upsample_matrices\",\n",
    "  \"num_conv_filters_dec_c\",\n",
    "  \"latent_dim_content\"\n",
    "])\n",
    "\n",
    "DECODER_S_ARGS = copy(COMMON_ARGS)\n",
    "DECODER_S_ARGS.extend([\n",
    "    \"upsample_matrices\",\n",
    "    \"num_conv_filters_dec_s\",\n",
    "    \"latent_dim_content\",\n",
    "    \"latent_dim_style\",\n",
    "    \"n_timeframes\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dc61b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _steal_attributes_from_child(self, child: str, attributes: Union[List[str], str]):\n",
    "\n",
    "    '''\n",
    "       Make attributes from an object's child visible from the (parent) object's namespace\n",
    "    '''\n",
    "\n",
    "    child = getattr(self, child)\n",
    "\n",
    "    if isinstance(attributes, str):\n",
    "        attributes = [attributes]\n",
    "\n",
    "    for attribute in attributes:\n",
    "        setattr(self, attribute, getattr(child, attribute))\n",
    "    return self\n",
    "\n",
    "\n",
    "class AutoencoderTemporalSequence(nn.Module):\n",
    "\n",
    "    def __init__(self, enc_config, dec_c_config, dec_s_config, z_aggr_function=\"dft\", n_timeframes=None, phase_embedding_method=\"exp\"):\n",
    "\n",
    "        super(AutoencoderTemporalSequence, self).__init__()\n",
    "        \n",
    "        self.encoder = EncoderTemporalSequence(\n",
    "            enc_config, \n",
    "            z_aggr_function, \n",
    "            n_timeframes=n_timeframes\n",
    "        )\n",
    "        \n",
    "        self.decoder = DecoderTemporalSequence(\n",
    "            dec_c_config, \n",
    "            dec_s_config, \n",
    "            phase_embedding_method\n",
    "        )\n",
    "\n",
    "        self._is_variational = self.encoder.encoder_3d_mesh._is_variational\n",
    "\n",
    "        self.template_mesh = dec_c_config[\"template\"]\n",
    "\n",
    "                    \n",
    "    def forward(self, s_t):\n",
    "\n",
    "        z = self.encoder(s_t)\n",
    "        avg_s, shat_t = self.decoder(z)\n",
    "                        \n",
    "        return z, avg_s, shat_t\n",
    "\n",
    "    \n",
    "    def set_mode(self, mode: str):\n",
    "        '''\n",
    "        params:\n",
    "          mode: \"training\" or \"testing\"\n",
    "        '''\n",
    "        self._mode = mode\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "class EncoderTemporalSequence(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder_config, z_aggr_function, phase_embedding=None, n_timeframes=None):\n",
    "\n",
    "        super(EncoderTemporalSequence, self).__init__()\n",
    "        encoder_config = copy(encoder_config)\n",
    "        encoder_config[\"latent_dim\"] = encoder_config.pop(\"latent_dim_content\") + encoder_config.pop(\"latent_dim_style\")\n",
    "        \n",
    "        self.latent_dim = encoder_config[\"latent_dim\"]\n",
    "        self.encoder_3d_mesh = Encoder3DMesh(**encoder_config)\n",
    "\n",
    "        self = _steal_attributes_from_child(self, child=\"encoder_3d_mesh\", attributes=[\"matrices\"])\n",
    "\n",
    "        self.z_aggr_function = self._get_z_aggr_function(z_aggr_function, n_timeframes)\n",
    "        self.phase_embedding = phase_embedding\n",
    "\n",
    "\n",
    "    def _get_z_aggr_function(self, z_aggr_function, n_timeframes=None):\n",
    "\n",
    "        if z_aggr_function == \"mean\":\n",
    "            if phase_embedding is None:\n",
    "                exit(\"The temporal aggregation cannot be the mean if phase information is not embedded into the input meshes.\")\n",
    "            z_aggr_function = Mean_Aggregator()\n",
    "\n",
    "        elif z_aggr_function.lower() in {\"fcn\", \"fully_connected\"}:\n",
    "            self.n_timeframes = n_timeframes\n",
    "            z_aggr_function = FCN_Aggregator(\n",
    "                features_in=n_timeframes * self.latent_dim,\n",
    "                features_out=(self.latent_dim)\n",
    "            )\n",
    "\n",
    "        elif z_aggr_function.lower() in {\"dft\", \"discrete_fourier_transform\"}:\n",
    "            self.n_timeframes = n_timeframes\n",
    "            z_aggr_function = DFT_Aggregator(\n",
    "                features_in=(n_timeframes // 2 + 1) * 2 * (self.latent_dim),\n",
    "                features_out=(self.latent_dim)\n",
    "            )\n",
    "\n",
    "        return z_aggr_function\n",
    "\n",
    "\n",
    "    def set_mode(self, mode: str):\n",
    "        '''\n",
    "        params:\n",
    "          mode: \"training\" or \"testing\"\n",
    "        '''\n",
    "        self._mode = mode\n",
    "\n",
    "\n",
    "    def encoder(self, x):\n",
    "                \n",
    "        self.n_timeframes = x.shape[1]\n",
    "\n",
    "        # Iterate through time points\n",
    "        bottleneck_t = [ self.encoder_3d_mesh(x[:, i, :]) for i in range(self.n_timeframes) ]\n",
    "        mu = [ bottleneck[\"mu\"] for bottleneck in bottleneck_t ]\n",
    "\n",
    "        # If one element (and therefore all elements) are None, replace the whole thing with None\n",
    "        log_var = [ bottleneck[\"log_var\"] for bottleneck in bottleneck_t ] if bottleneck_t[0][\"log_var\"] is not None else None\n",
    "\n",
    "        mu = torch.cat(mu).reshape(-1, self.n_timeframes, self.latent_dim)\n",
    "        mu = self.z_aggr_function(mu)\n",
    "\n",
    "        if log_var is not None:\n",
    "            log_var_t = torch.cat(log_var).reshape(-1, self.n_timeframes, self.latent_dim)\n",
    "            log_var = self.z_aggr_function(log_var_t)\n",
    "\n",
    "        bottleneck = {\"mu\": mu, \"log_var\": log_var}\n",
    "        return bottleneck\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    \n",
    "##########################################################################################\n",
    "\n",
    "class DecoderStyle(nn.Module):\n",
    "\n",
    "    def __init__(self, decoder_config: dict, phase_embedding_method: str, n_timeframes: Union[int, None]=None):\n",
    "\n",
    "        super(DecoderStyle, self).__init__()\n",
    "\n",
    "        decoder_config = copy(decoder_config)\n",
    "        self.n_timeframes = decoder_config.pop(\"n_timeframes\")\n",
    "        self.phase_embedding = self._get_phase_embedding(phase_embedding_method, self.n_timeframes)\n",
    "\n",
    "        decoder_config = copy(decoder_config)\n",
    "        decoder_config[\"latent_dim\"] = decoder_config.pop(\"latent_dim_content\") + 2 * decoder_config.pop(\"latent_dim_style\")\n",
    "        decoder_config[\"num_conv_filters_dec\"] = decoder_config.pop(\"num_conv_filters_dec_s\")\n",
    "\n",
    "        self.decoder_3d = Decoder3DMesh(**decoder_config)\n",
    "\n",
    "\n",
    "    def  _get_phase_embedding(self, phase_embedding_method, n_timeframes):\n",
    "\n",
    "        if phase_embedding_method.lower() in [\"inverse_dft\", \"dft\"]:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        elif phase_embedding_method.lower() in [\"concatenation\", \"concat\"]:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        elif phase_embedding_method.lower() in [\"exponential_v1\", \"exp_v1\", \"exp\"]:\n",
    "            return PhaseTensor(version=\"version_1\")\n",
    "\n",
    "        elif phase_embedding_method.lower() in [\"exponential_v2\", \"exp_v2\"]:\n",
    "            return PhaseTensor(version=\"version_2\")\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Method of phase embedding {phase_embedding_method} has not been recognised.\")\n",
    "\n",
    "\n",
    "    def _process_one_timeframe(self, z_c, phased_z_s, t):\n",
    "\n",
    "        z_s_t = phased_z_s[:, t, ...]\n",
    "        z = torch.cat([z_c, z_s_t], axis=-1)\n",
    "        s_t = self.decoder_3d(z)\n",
    "        s_t = s_t.unsqueeze(1)\n",
    "        return s_t\n",
    "\n",
    "\n",
    "    def forward(self, z_c, z_s, n_timeframes):\n",
    "\n",
    "        phased_z_s = z_s.unsqueeze(TIME_DIMENSION).repeat(1, self.n_timeframes, *[1 for x in z_s.shape[1:]])\n",
    "        phased_z_s = self.phase_embedding(phased_z_s)\n",
    "        s_out = [ self._process_one_timeframe(z_c, phased_z_s, t) for t in range(n_timeframes) ]\n",
    "        s_out = torch.cat(s_out, dim=1)\n",
    "                \n",
    "        return s_out\n",
    "\n",
    "\n",
    "\n",
    "class DecoderTemporalSequence(nn.Module):\n",
    "\n",
    "    def __init__(self, decoder_c_config, decoder_s_config, phase_embedding_method, n_timeframes=None):\n",
    "\n",
    "        super(DecoderTemporalSequence, self).__init__()\n",
    "\n",
    "        decoder_c_config = copy(decoder_c_config)\n",
    "        decoder_c_config[\"num_conv_filters_dec\"] = decoder_c_config.pop(\"num_conv_filters_dec_c\")\n",
    "        decoder_c_config[\"latent_dim\"] = decoder_c_config.pop(\"latent_dim_content\")\n",
    "\n",
    "        self.template_mesh = decoder_c_config[\"template\"]\n",
    "        self.latent_dim_content = decoder_c_config[\"latent_dim\"]\n",
    "        self.latent_dim_style = decoder_s_config[\"latent_dim_style\"]\n",
    "\n",
    "        self.decoder_content = Decoder3DMesh(**decoder_c_config)\n",
    "        self.decoder_style = DecoderStyle(decoder_s_config, phase_embedding_method, n_timeframes)\n",
    "\n",
    "        self = _steal_attributes_from_child(self, child=\"decoder_content\", attributes=[\"matrices\"])\n",
    "\n",
    "\n",
    "    def set_mode(self, mode: str):\n",
    "        '''\n",
    "        params:\n",
    "          mode: \"training\" or \"testing\"\n",
    "        '''\n",
    "        self._mode = mode\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "\n",
    "        bottleneck = self._partition_z(z[\"mu\"], z[\"log_var\"])\n",
    "        z_c, z_s = bottleneck[\"mu_c\"], bottleneck[\"mu_s\"]\n",
    "        avg_shape = self.decoder_content(z_c)\n",
    "        def_field_t = self.decoder_style(z_c, z_s, self.decoder_style.n_timeframes)\n",
    "        shape_t = avg_shape.unsqueeze(TIME_DIMENSION) + def_field_t\n",
    "        return avg_shape, shape_t\n",
    "\n",
    "\n",
    "    def _partition_z(self, mu, log_var=None):\n",
    "\n",
    "        bottleneck = {\n",
    "            \"mu_c\": mu[:, :self.latent_dim_content],\n",
    "            \"mu_s\": mu[:, self.latent_dim_content:]\n",
    "        }\n",
    "\n",
    "        if log_var is not None:\n",
    "            bottleneck.update({\n",
    "                \"log_var_c\": log_var[:, :self.latent_dim_content],\n",
    "                \"log_var_s\": log_var[:, self.latent_dim_content:]\n",
    "            })\n",
    "\n",
    "        return bottleneck\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e398999",
   "metadata": {},
   "source": [
    "### Data modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74628d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.load_config import load_yaml_config\n",
    "config = load_yaml_config(\"config_files/config_folded_c_and_s.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe63aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = { \n",
    "#   \"N\": 100, \"T\": 20, \"mesh_resolution\": 10,\n",
    "#   \"l_max\": 2, \"freq_max\": 2, \n",
    "#   \"amplitude_static_max\": 0.3, \"amplitude_dynamic_max\": 0.1, \n",
    "#   \"random_seed\": 144\n",
    "# }\n",
    "\n",
    "# preproc_params = EasyDict({\"center_around_mean\": False})\n",
    "\n",
    "mesh_ds = SyntheticMeshesDataset(config.dataset.parameters, config.dataset.preprocessing)\n",
    "mesh_dm = SyntheticMeshesDM(mesh_ds)\n",
    "mesh_dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8757049",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mesh_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30b3892",
   "metadata": {},
   "source": [
    "---\n",
    "# <center> --- Tests --- <center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a5b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helpers import get_coma_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef05483",
   "metadata": {},
   "outputs": [],
   "source": [
    "coma_args = get_coma_args(config, mesh_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb0bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_params = {\n",
    "    \"phase_input\" : False, \n",
    "    \"num_conv_filters_enc\" : [16, 16, 16, 16], \n",
    "    \"num_features\" : 3,\n",
    "    \"cheb_polynomial_order\" : [6, 6, 6, 6],\n",
    "    \"n_layers\" : 4,\n",
    "    \"n_nodes\" : coma_args.n_nodes,\n",
    "    \"is_variational\" : True,\n",
    "    \"latent_dim\" : 16,\n",
    "    \"template\": coma_args.template,\n",
    "    \"adjacency_matrices\": coma_args.adjacency_matrices,\n",
    "    \"downsample_matrices\": coma_args.downsample_matrices,\n",
    "}\n",
    "\n",
    "encoder = Encoder3DMesh(**enc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de333eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = EasyDict(next(iter(mesh_dm.train_dataloader())))\n",
    "\n",
    "encoder.forward_conv_stack(x.s_t, preserve_graph_structure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ed7e44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
