{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    os.environ[\"CARDIAC_MOTION_REPO\"] = f\"{os.environ['HOME']}/01_repos/CardiacMotion\"\n",
    "    repo_dir = os.environ.get(\"CARDIAC_MOTION_REPO\")\n",
    "    os.chdir(repo_dir)\n",
    "except FileNotFoundError:\n",
    "    os.environ[\"HOME\"] = \"/root\"\n",
    "    os.environ[\"CARDIAC_MOTION_REPO\"] = f\"{os.environ['HOME']}/01_repos/CardiacMotion\"\n",
    "    repo_dir = os.environ.get(\"CARDIAC_MOTION_REPO\")\n",
    "    os.chdir(repo_dir)\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "import os, sys\n",
    "import glob\n",
    "import re\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from typing import Union, Dict, List, Optional\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from utils.CardioMesh.CardiacMesh import transform_mesh\n",
    "\n",
    "from easydict import EasyDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "from main_autoencoder_cardiac import CardiacMeshPopulationDataset, CardiacMeshPopulationDM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "`CardioMesh.CardiacMeshPopulation.py`\n",
    "\n",
    "Example of usage:\n",
    "    \n",
    "```\n",
    "mesh_population = CardiacMeshPopulation(\n",
    "  root_path = \"data/cardio/Results\",\n",
    "  N_subj = None\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "`(ID, phase) -> path`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "I am assuming LV is being used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"data/cardio/Results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Compute Procrustes transforms for additional meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import orthogonal_procrustes\n",
    "from IPython import embed\n",
    "import logging\n",
    "\n",
    "def mse(s1, s2=None):\n",
    "    if s2 is None:\n",
    "        s2 = torch.zeros_like(s1)\n",
    "    return ((s1-s2)**2).sum(-1).mean(-1)\n",
    "\n",
    "def get_3d_mesh(ids, root_folder):\n",
    "    \n",
    "    for id in ids:\n",
    "        npy_file = f\"{root_folder}/{id}/models/fhm_time001.npy\"\n",
    "        pc  = np.load(npy_file)\n",
    "        yield id, pc\n",
    "        \n",
    "\n",
    "def get_4d_mesh(ids, root_folder, timepoints=list(range(1,51))):\n",
    "    \n",
    "    for id in ids:\n",
    "        for t in timepoints:\n",
    "            npy_file = f\"{root_folder}/{id}/models/fhm_time{str(t).zfill(3)}.npy\"\n",
    "            pc  = np.load(npy_file)\n",
    "        yield id, pc\n",
    "\n",
    "\n",
    "\n",
    "def generalisedProcrustes(point_clouds: np.array, ids: List, template_mesh=None, scaling=False, logger=logging.getLogger()):\n",
    "\n",
    "\n",
    "    logger.info(\"Performing Procrustes analysis with scaling\")\n",
    "    if template_mesh is None:\n",
    "        template_mesh = point_clouds[0]\n",
    "\n",
    "    old_disparity, disparity = 0, 1  # random values\n",
    "    it_count = 0\n",
    "    \n",
    "    transforms = {}            \n",
    "\n",
    "    centroids = point_clouds.mean(axis=1)\n",
    "    for i, id in enumerate(ids):\n",
    "        point_clouds[i] -= centroids[i] \n",
    "        transforms[id] = {}\n",
    "        transforms[id][\"traslation\"] = centroids[i]\n",
    "\n",
    "\n",
    "    while abs(old_disparity - disparity) / disparity > 1e-2 and disparity:\n",
    "\n",
    "        old_disparity = disparity\n",
    "        disparity = []\n",
    "\n",
    "        for i, id in tqdm(enumerate(ids)):\n",
    "\n",
    "            # Docs: https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.procrustes.html\n",
    "            if scaling:\n",
    "                mtx1, mtx2, _disparity = procrustes(template_mesh, point_clouds[i])\n",
    "                point_clouds[i] = np.array(mtx2)  # if self.procrustes_scaling else np.array(mtx1)\n",
    "\n",
    "            else:\n",
    "                # Docs: https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.orthogonal_procrustes.html\n",
    "                # Note that the arguments are swapped with respect to the previous @procrustes function\n",
    "                R, s = orthogonal_procrustes(point_clouds[i], template_mesh)\n",
    "                # Rotate\n",
    "                point_clouds[i] = np.dot(point_clouds[i], R)  # * s\n",
    "                # Mean point-wise MSE\n",
    "                _disparity = mse(point_clouds[i], template_mesh) \n",
    "                disparity.append(_disparity)\n",
    "\n",
    "                if it_count == 0:\n",
    "                    transforms[id][\"rotation\"] = R #, \"scaling\": s}\n",
    "                else:\n",
    "                    transforms[id][\"rotation\"] = R.dot(transforms[id][\"rotation\"]) #, \"scaling\": transforms[i][\"scaling\"] * s}\n",
    "\n",
    "        template_mesh = point_clouds.mean(axis=0)\n",
    "        disparity = np.array(disparity).mean(axis=0)\n",
    "        it_count += 1\n",
    "        \n",
    "    #self.procrustes_aligned = True\n",
    "    logger.info(\n",
    "        \"Generalized Procrustes analysis with scaling performed after %s iterations\"\n",
    "        % it_count\n",
    "    )\n",
    "\n",
    "    return transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCRUSTES_FILE = \"utils/CardioMesh/data/procrustes_transforms_FHM_35k.pkl\"\n",
    "procrustes_transforms = pkl.load(open(PROCRUSTES_FILE, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# paths = glob.glob(\"/mnt/data/workshop/workshop-user1/datasets/meshes/Results_*/*/models/FHM_res_0.1_time001.npy\")\n",
    "# regex = \"/mnt/data/workshop/workshop-user1/datasets/meshes/Results_.*/(.*)/models/FHM_res_0.1_time001.npy\"\n",
    "# regex = re.compile(regex)\n",
    "# meshes_fhmed = {regex.match(path).group(1): np.load(path) for path in paths}\n",
    "# pkl.dump(meshes_fhmed, open(\"/home/user/01_repos/CardiacCOMA/data/FHM_meshes_at_ED_all_my_segmentation_61225.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MESHES_FHM_FILE = \"/home/user/01_repos/CardiacCOMA/data/FHM_meshes_at_ED_all_my_segmentation_61225.pkl\"\n",
    "meshes = pkl.load(open(MESHES_FHM_FILE, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ids = set(meshes.keys()).intersection(set(procrustes_transforms.keys()))\n",
    "procrustes_transforms = {k:procrustes_transforms[k] for k in common_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes_original_aligned = [transform_mesh(meshes[id], **procrustes_transforms[id]) for id in procrustes_transforms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes_original_aligned = np.array(meshes_original_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_mesh = meshes_original_aligned.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_mesh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes_npy = np.array(list(meshes.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(meshes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "procrustes_transforms = generalisedProcrustes(\n",
    "    point_clouds=meshes_npy,\n",
    "    ids=ids,\n",
    "    template_mesh=template_mesh\n",
    ")\n",
    "\n",
    "PROCRUSTES_FHM_FULL = \"utils/VTKHelpers/data/procrustes_transforms_FHM_61k.pkl\"\n",
    "pkl.dump(procrustes_transforms, open(PROCRUSTES_FHM_FULL, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = EasyDict(\n",
    "    pkl.load(open(\"utils/VTKHelpers/data/faces_and_downsampling_mtx_frac_0.1_LV.pkl\", \"rb\"))\n",
    ").new_faces\n",
    "\n",
    "template = EasyDict({\n",
    "   \"v\": transform_mesh(np.load(\n",
    "       f\"{root_path}/1000215/models/FHM_time001.npy\"), \n",
    "       **procrustes_transforms[\"1000215\"]\n",
    "   ),\n",
    "   \"f\": faces\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cardiac_dataset = CardiacMeshPopulationDataset(\n",
    "    root_path, \n",
    "    procrustes_transforms=\"utils/VTKHelpers/data/procrustes_transforms_FHM_35k.pkl\",\n",
    "    faces=faces,\n",
    "    template_mesh=template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Compute mean across timepoints and across subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pp = []\n",
    "for i, k in enumerate(cardiac_dataset):\n",
    "    print(i)\n",
    "    pp.append(k[\"time_avg_s\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_popmean = torch.stack(pp).mean(0).numpy()\n",
    "POPMEAN_SHAPE = \"data/LV_shape_mean_across_timepoints.npy\"\n",
    "np.save(POPMEAN_SHAPE, s_popmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_avg_s = [ k[\"time_avg_s\"] in cardiac_dataset ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "cardiac_mesh_dm = CardiacMeshPopulationDM(cardiac_dataset, batch_size=32)\n",
    "cardiac_mesh_dm.setup()\n",
    "len(cardiac_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_idx_w = widgets.IntSlider(min=1, max=len(cardiac_dataset))\n",
    "\n",
    "def generate_gif(mesh4D, faces, filename, camera_position='xy', show_edges=False, **kwargs):\n",
    "        \n",
    "        '''\n",
    "        Produces a gif file representing the motion of the input mesh.\n",
    "        \n",
    "        params:\n",
    "          ::mesh4D:: a sequence of Trimesh mesh objects.\n",
    "          ::faces:: array of F x 3 containing the indices of the mesh's triangular faces.\n",
    "          ::filename:: the name of the output gif file.\n",
    "          ::camera_position:: camera position for pyvista plotter (check relevant docs)\n",
    "          \n",
    "        return:\n",
    "          None, only produces the gif file.\n",
    "        '''\n",
    "\n",
    "        import pyvista as pv\n",
    "        \n",
    "        connectivity = np.c_[np.ones(faces.shape[0]) * 3, faces].astype(int)\n",
    "                \n",
    "        pv.set_plot_theme(\"document\")\n",
    "        os.makedirs(os.path.dirname(\"./\"+filename) , exist_ok=True)\n",
    "        \n",
    "        # plotter = pv.Plotter(shape=(1, len(camera_positions)), notebook=False, off_screen=True)\n",
    "        pv.start_xvfb()\n",
    "        plotter = pv.Plotter(notebook=False, off_screen=True)\n",
    "            \n",
    "        # Open a gif\n",
    "        plotter.open_gif(filename)\n",
    "\n",
    "        try:\n",
    "            # if mesh3D is torch.Tensor, this your should run OK\n",
    "            mesh4D = mesh4D.cpu().numpy()[0].astype(\"float32\")\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "        kk = pv.PolyData(mesh4D[0], connectivity)\n",
    "        # plotter.add_mesh(kk, smooth_shading=True, opacity=0.5 )#, show_edges=True)\n",
    "        plotter.add_mesh(kk, show_edges=show_edges, opacity=0.5, color=\"red\") \n",
    "        \n",
    "        for t, _ in enumerate(mesh4D):\n",
    "            kk = pv.PolyData(mesh4D[t], connectivity)\n",
    "            plotter.camera_position = camera_position\n",
    "            plotter.update_coordinates(kk.points, render=False)\n",
    "            plotter.render()             \n",
    "            plotter.write_frame()\n",
    "        \n",
    "        plotter.close()\n",
    "        \n",
    "        return filename\n",
    "\n",
    "@interact\n",
    "def show_gif(subj_idx=subj_idx_w):\n",
    "    \n",
    "    from IPython.display import HTML\n",
    "    import base64\n",
    "        \n",
    "    # subj_id = cardiac_dataset.ids[subj_id]                \n",
    "    \n",
    "    gifpath = generate_gif(\n",
    "        torch.stack(pp).mean(0), #cardiac_dataset[subj_idx], \n",
    "        faces, filename=\"kk.gif\", camera_position=\"xz\"\n",
    "    )\n",
    "    \n",
    "    b64 = base64.b64encode(\n",
    "        open(gifpath,'rb').read()\n",
    "    ).decode('ascii')\n",
    "    \n",
    "    display(HTML(f'<img src=\"data:image/gif;base64,{b64}\" />'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
