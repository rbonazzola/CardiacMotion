{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import os, sys\n",
    "import glob\n",
    "import torch\n",
    "from pprint import pprint\n",
    "from easydict import EasyDict\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "os.environ['HOME'] = \"/home/user\"\n",
    "os.environ['CARDIAC_MOTION_REPO'] = os.environ[\"HOME\"] + \"/01_repos/CardiacMotion\"\n",
    "os.chdir(os.environ['CARDIAC_MOTION_REPO'])\n",
    "\n",
    "sys.path.append(os.environ['CARDIAC_MOTION_REPO'])\n",
    "\n",
    "from utils.image_helpers import generate_gif, merge_gifs_horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI = f\"{os.environ['HOME']}/01_repos/CardiacMotion/mlruns/\"\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_URI = mlflow.tracking.get_tracking_uri()\n",
    "# EXPERIMENT_ID = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "# PREFIX = f\"{MLFLOW_URI}/{EXPERIMENT_ID}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_yamls = [f\"{PREFIX}/{run}/meta.yaml\" for run in os.listdir(PREFIX) if os.path.exists(f\"{PREFIX}/{run}/meta.yaml\")]\n",
    "# \n",
    "# count = 0\n",
    "# for meta_yaml_path in meta_yamls:\n",
    "#     meta_yaml = yaml.safe_load(open(meta_yaml_path))    \n",
    "#     if meta_yaml['experiment_id'] != EXPERIMENT_ID:\n",
    "#         meta_yaml['experiment_id'] = EXPERIMENT_ID\n",
    "#         count += 1\n",
    "#         yaml.dump(meta_yaml, open(meta_yaml_path, \"wt\"))\n",
    "#         \n",
    "# if count != 0:\n",
    "#     print(f\"{count} runs's experiments were fixed to match the experiment of the parent folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose runs with good performance\n",
    "df = mlflow.search_runs(experiment_ids=[str(i) for i in range(2,9)])\n",
    "df = df[(df[\"metrics.val_rec_ratio_to_time_mean\"] < 1) & (df[\"params.dataset_n_timeframes\"] == '10')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# columns\n",
    "normalized_metrics = df.columns[df.columns.str.startswith(\"metrics.val_\") & df.columns.str.contains(\"ratio\")]\n",
    "\n",
    "dataset_params = df.columns[df.columns.str.startswith(\"params.dataset_\")].to_list()\n",
    "\n",
    "params = df.columns[df.columns.str.startswith(\"params.\")].to_list()\n",
    "\n",
    "arch_params = [\n",
    "    'params.n_channels_enc', \n",
    "    'params.n_channels_dec_c', \n",
    "    'params.n_channels_dec_s', \n",
    "    'params.latent_dim_c', \n",
    "    'params.latent_dim_s',\n",
    "    'params.z_aggr_function',\n",
    "    'params.reduction_factors',\n",
    "]\n",
    "\n",
    "# To not display columns that have the same value for all rows\n",
    "# https://stackoverflow.com/questions/57365283/how-to-show-columns-that-have-different-values-in-rows\n",
    "def diff_cols(df):\n",
    "    \n",
    "    my_cols = []\n",
    "    for col in df.columns:\n",
    "        if df[col].nunique(dropna=False) > 1:\n",
    "            my_cols.append(col)\n",
    "    return df[my_cols].copy()\n",
    "\n",
    "\n",
    "columns = [\"experiment_id\", \"run_id\"] + params + normalized_metrics.tolist()\n",
    "\n",
    "df_reduced = diff_cols(\n",
    "    df[columns].reset_index(drop=True)\n",
    ").sort_values(\"experiment_id\")\n",
    "\n",
    "df_reduced[\"partition\"] = df_reduced.experiment_id.apply(lambda expid: mlflow.get_experiment(expid).name)\n",
    "df_reduced = df_reduced.set_index(\"run_id\")\n",
    "df_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Get run IDs based on metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_runs = df_reduced.index\n",
    "\n",
    "kk = { tuple(df_reduced.loc[run, [\"partition\", \"metrics.val_rec_ratio_to_time_mean\"]]): run for run in good_runs }\n",
    "kk = {(k[0], round(k[1], 3)): v for k, v in kk.items()}\n",
    "\n",
    "run_w = widgets.Select(options=kk)\n",
    "run_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "runid = run_w.value\n",
    "expid = df_reduced.loc[run_w.value].experiment_id\n",
    "\n",
    "ckpt_dir = f\"{os.environ['HOME']}/01_repos/CardiacMotion/{expid}/{runid}/checkpoints\"\n",
    "ckpt_path = f\"{ckpt_dir}/{os.listdir(ckpt_dir)[0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_path = f\"/root/Rodrigo_repos/CardiacMotion/2/{run_w.value}/checkpoints/epoch=334-step=38524.ckpt\"\n",
    "\n",
    "# model_weights = torch.load(ckpt_path, map_location=torch.device('cpu'))[\"state_dict\"]\n",
    "model_weights = torch.load(ckpt_path)[\"state_dict\"]\n",
    "print(f\"Loaded weights from checkpoint:\\n {ckpt_path}\")\n",
    "# model_weights = EasyDict(model_weights)\n",
    "model_weights = EasyDict({k.replace(\"model.\", \"\"): v for k, v in model_weights.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Initialize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_autoencoder_cardiac import *\n",
    "from config.load_config import load_yaml_config\n",
    "\n",
    "from models.Model3D import Encoder3DMesh, Decoder3DMesh\n",
    "from models.Model4D import DECODER_C_ARGS, DECODER_S_ARGS, ENCODER_ARGS\n",
    "from models.Model4D import DecoderStyle, DecoderContent, DecoderTemporalSequence \n",
    "from models.Model4D import EncoderTemporalSequence, AutoencoderTemporalSequence\n",
    "from lightning.ComaLightningModule import CoMA_Lightning\n",
    "from models.lightning.EncoderLightningModule import TemporalEncoderLightning\n",
    "from models.TemporalAggregators import TemporalAggregator, FCN_Aggregator\n",
    "\n",
    "POLYNOMIAL_DEGREE = 10\n",
    "DOWNSAMPLING = 3\n",
    "\n",
    "config = load_yaml_config(\"config_folded_c_and_s.yaml\")\n",
    "config.network_architecture.convolution.parameters.polynomial_degree = [POLYNOMIAL_DEGREE] * 4\n",
    "config.network_architecture.pooling.parameters.downsampling_factors = [3, 3, 2, 2] # * 4\n",
    "config.network_architecture.latent_dim_c = 8 \n",
    "config.network_architecture.latent_dim_s = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "partition = df_reduced.loc[runid, [\"partition\"]].item()\n",
    "PARTITION = process.extractOne(partition, partitions.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "FACES_FILE = \"utils/CardioMesh/data/faces_and_downsampling_mtx_frac_0.1_LV.pkl\"\n",
    "\n",
    "MEAN_ACROSS_CYCLE_FILE = f\"utils/CardioMesh/data/cached/mean_shape_time_avg__{PARTITION}.npy\"\n",
    "PROCRUSTES_FILE = f\"utils/CardioMesh/data/cached/procrustes_transforms_{PARTITION}.pkl\"    \n",
    "SUBSETTING_MATRIX_FILE = f\"/home/user/01_repos/CardioMesh/data/cached/subsetting_matrix_{PARTITION}.pkl\" \n",
    "\n",
    "subsetting_matrix = pkl.load(open(SUBSETTING_MATRIX_FILE, \"rb\"))\n",
    "\n",
    "ID = \"1000511\"\n",
    "fhm_mesh = Cardiac3DMesh(\n",
    "   filename=f\"/mnt/data/workshop/workshop-user1/datasets/meshes/Results_Yan/{ID}/models/FHM_res_0.1_time001.npy\",\n",
    "   faces_filename=\"/home/user/01_repos/CardioMesh/data/faces_fhm_10pct_decimation.csv\",\n",
    "   subpart_id_filename=\"/home/user/01_repos/CardioMesh/data/subpartIDs_FHM_10pct.txt\"\n",
    ")\n",
    "\n",
    "template = EasyDict({\n",
    "  \"v\": np.load(MEAN_ACROSS_CYCLE_FILE),\n",
    "  \"f\": fhm_mesh[partitions[PARTITION]].f\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### Cardiac dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "NT = 10 # config.dataset.parameters.T\n",
    "cardiac_dataset = CardiacMeshPopulationDataset(\n",
    "    root_path=\"data/cardio/Results\", \n",
    "    procrustes_transforms=PROCRUSTES_FILE,\n",
    "    faces=template.f,\n",
    "    subsetting_matrix=subsetting_matrix,\n",
    "    template_mesh= template,\n",
    "    N_subj=1000,\n",
    "    phases_filter=1+(50/NT)*np.array(range(NT))\n",
    ")\n",
    "\n",
    "print(f\"Length of dataset: {len(cardiac_dataset)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datamodule = get_datamodule(config.dataset, batch_size=config.batch_size)\n",
    "\n",
    "mesh_dm = CardiacMeshPopulationDM(cardiac_dataset, batch_size=32)\n",
    "mesh_dm.setup()\n",
    "\n",
    "x = EasyDict(next(iter(mesh_dm.train_dataloader())))\n",
    "\n",
    "mesh_template = mesh_dm.dataset.template_mesh\n",
    "coma_args = get_coma_args(config)\n",
    "coma_matrices = get_coma_matrices(config, mesh_template, PARTITION)\n",
    "coma_args.update(coma_matrices)\n",
    "\n",
    "enc_config = EasyDict({k: v for k, v in coma_args.items() if k in ENCODER_ARGS})\n",
    "encoder = Encoder3DMesh(**enc_config)\n",
    "\n",
    "enc_config.latent_dim = config.network_architecture.latent_dim_c + config.network_architecture.latent_dim_s \n",
    "\n",
    "h = encoder.forward_conv_stack(x.s_t, preserve_graph_structure=False)\n",
    "\n",
    "z_aggr = FCN_Aggregator(\n",
    "    features_in = NT*h.shape[-1],\n",
    "    features_out= enc_config.latent_dim\n",
    ")\n",
    "\n",
    "t_encoder = EncoderTemporalSequence(\n",
    "    encoder3d = encoder,\n",
    "    z_aggr_function=z_aggr\n",
    ")\n",
    "\n",
    "decoder_config_c = EasyDict({ k:v for k,v in coma_args.items() if k in DECODER_C_ARGS })\n",
    "decoder_config_s = EasyDict({ k:v for k,v in coma_args.items() if k in DECODER_S_ARGS })    \n",
    "decoder_content = DecoderContent(decoder_config_c)\n",
    "decoder_style = DecoderStyle(decoder_config_s, phase_embedding_method=\"exp_v1\")\n",
    "t_decoder = DecoderTemporalSequence(decoder_content, decoder_style)\n",
    "    \n",
    "t_ae = AutoencoderTemporalSequence(\n",
    "    encoder=t_encoder,\n",
    "    decoder=t_decoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ae.load_state_dict(model_weights)\n",
    "t_ae = t_ae.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_weights = torch.load(\"/home/user/01_repos/CardiacMotion/4/8a320f3c1d2b4d799da91be75205ca81/checkpoints/epoch=344-step=252884.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lit_module = CoMA_Lightning(\n",
    "#     model=t_ae, \n",
    "#     loss_params=config.loss, \n",
    "#     optimizer_params=config.optimizer,\n",
    "#     additional_params=config,\n",
    "#     mesh_template=mesh_template\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Load input meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_dl = torch.utils.data.DataLoader(cardiac_dataset, batch_size=8, num_workers=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Generate animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[\"s_t\"] = x[\"s_t\"].to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = t_ae(x[\"s_t\"])\n",
    "s_t, s_hat_t = x[\"s_t\"], output[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyvista as pv\n",
    "#         \n",
    "# connectivity = np.c_[np.ones(template.f.shape[0]) * 3, template.f].astype(int)\n",
    "# pv.set_plot_theme(\"document\")\n",
    "# pv.start_xvfb()\n",
    "# \n",
    "# plotter = pv.Plotter(notebook=False, off_screen=True)\n",
    "# FILENAME = f\"test_{PARTITION}_rec.gif\"\n",
    "# plotter.open_gif(FILENAME)\n",
    "# \n",
    "# mesh4D = t_ae(x[\"s_t\"])[2]\n",
    "# # mesh4D = x[\"s_t\"]\n",
    "# mesh4D = mesh4D.detach().cpu().numpy()[0].astype(\"float32\")\n",
    "# \n",
    "# pv_mesh = pv.PolyData(mesh4D[0], connectivity)\n",
    "# plotter.add_mesh(pv_mesh, show_edges=False, opacity=0.5, color=\"red\") \n",
    "# \n",
    "# for t, _ in tqdm(enumerate(mesh4D)):\n",
    "#     # print(t)\n",
    "#     kk = pv.PolyData(mesh4D[t], connectivity)\n",
    "#     plotter.camera_position = \"xz\" # camera_position\n",
    "#     plotter.update_coordinates(kk.points, render=False)\n",
    "#     plotter.render()             \n",
    "#     plotter.write_frame()\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Generate gif's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_ids = list(range(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = template.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{os.environ['HOME']}/01_repos/CardiacMotion/mlruns/{expid}/{runid}/artifacts/output/gif\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ODIR = f\"{os.environ['HOME']}/01_repos/CardiacMotion/mlruns/{expid}/{runid}/artifacts/output/gif\"        \n",
    "# os.makedirs(ODIR)\n",
    "\n",
    "for subj_id in subj_ids:\n",
    "\n",
    "    for camera in [\"xz\", \"xy\", \"yz\"]:    \n",
    "        for suffix, st in {\"original\": s_t, \"reconstruction\": s_hat_t}.items():\n",
    "            mesh4D = st.detach().cpu().numpy().astype(\"float32\")[subj_id]        \n",
    "            gifpath = generate_gif(\n",
    "                mesh4D,\n",
    "                faces, \n",
    "                camera_position=camera,\n",
    "                filename=f\"{ODIR}/id{subj_id}_{suffix}_{camera}.gif\", \n",
    "            )\n",
    "        \n",
    "        merge_gifs_horizontally(\n",
    "            f\"{ODIR}/id{subj_id}_original_{camera}.gif\", \n",
    "            f\"{ODIR}/id{subj_id}_reconstruction_{camera}.gif\", \n",
    "            f\"{ODIR}/id{subj_id}_{camera}.gif\"\n",
    "        )\n",
    "        \n",
    "        os.remove(f\"{ODIR}/id{subj_id}_original_{camera}.gif\")\n",
    "        os.remove(f\"{ODIR}/id{subj_id}_reconstruction_{camera}.gif\")\n",
    "\n",
    "#b64 = base64.b64encode(\n",
    "#  open(gifpath,'rb').read()\n",
    "#).decode('ascii')\n",
    "#b64 = base64.b64encode(\n",
    "#    open(gifpath,'rb').read()\n",
    "#).decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_gif(subj_id=widgets.IntSlider(min=0,max=63)):\n",
    "    \n",
    "    # subj_id = cardiac_dataset.ids[subj_id]                \n",
    "    \n",
    "    gifpath = generate_gif(\n",
    "        torch.stack(pp).mean(0), #cardiac_dataset[subj_idx], \n",
    "        faces, filename=\"kk.gif\", camera_position=\"xz\"\n",
    "    )\n",
    "    \n",
    "    b64 = base64.b64encode(\n",
    "        open(gifpath,'rb').read()\n",
    "    ).decode('ascii')\n",
    "    \n",
    "    display(HTML(f'<img src=\"data:image/gif;base64,{b64}\" />'))       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### Save $\\textbf{z}$ to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "zs = []\n",
    "\n",
    "for i, x in tqdm(enumerate(mesh_dl)):\n",
    "    \n",
    "    # if (i % 10) == 0:\n",
    "    # print(i)\n",
    "        \n",
    "    if i < (len(zs)-1):\n",
    "        continue\n",
    "    \n",
    "    x['s_t'] = x['s_t'].to(\"cuda:0\")\n",
    "    z = t_ae.encoder(x['s_t'])\n",
    "    z = z['mu'].detach().cpu().numpy()\n",
    "    zs.append(z)\n",
    "    \n",
    "    \n",
    "    # zs.append(z)\n",
    "    torch.cuda.empty_cache() \n",
    "\n",
    "zs_concat = np.concatenate(zs)\n",
    "z_df = pd.DataFrame(zs_concat, index=cardiac_dataset.ids)\n",
    "del zs_concat, zs\n",
    "\n",
    "# colnames before: 0, 1, 2, 3\n",
    "z_df.columns = [ f\"z{str(i).zfill(3)}\" for i in range(16) ]\n",
    "# colnames after: z000, z001, z002, z003\n",
    "\n",
    "z_df = z_df.reset_index().rename({\"index\": \"ID\"}, axis=1)\n",
    "z_df.head()\n",
    "\n",
    "MLRUNS_DIR = \"/mnt/data/workshop/workshop-user1/output/CardiacMotion/mlruns\"\n",
    "# RUN_ID = \"8c1ffa20cacc4b6c88e18159e01867b4\"\n",
    "ZFILE = f\"{MLRUNS_DIR}/{expid}/{runid}/artifacts/latent_vector.csv\"\n",
    "z_df.to_csv(ZFILE, index=False)\n",
    "print(ZFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "$\\textbf{z}$ correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "z_corr_df = z_df.corr().abs()\n",
    "dendrogram = hierarchy.linkage(z_corr_df, method='average')\n",
    "reordered_matrix = z_corr_df.iloc[hierarchy.leaves_list(dendrogram), hierarchy.leaves_list(dendrogram)]\n",
    "\n",
    "sns.heatmap(\n",
    "    # z_corr_df, \n",
    "    reordered_matrix, \n",
    "    cmap='Greys', \n",
    "    xticklabels=True, yticklabels=True,    \n",
    ");"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
