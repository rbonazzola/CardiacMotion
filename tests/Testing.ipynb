{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "from config.load_config import load_yaml_config, to_dict, recursive_namespace\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "from importlib import reload\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import models.Model3D as Model3D; Model3D = reload(module=Model3D)\n",
    "import models.Model4D as Model4D; Model4D = reload(module=Model4D)\n",
    "import models.lightning.EncoderLightningModule as EncoderLightningModule\n",
    "\n",
    "EncoderLightningModule = reload(module=EncoderLightningModule)\n",
    "EncoderTemporalSequence = Model4D.EncoderTemporalSequence\n",
    "CineComaEncoder = EncoderLightningModule.CineComaEncoder\n",
    "DecoderStyle = Model4D.DecoderStyle\n",
    "DecoderTemporalSequence = Model4D.DecoderTemporalSequence\n",
    "AutoencoderTemporalSequence = Model4D.AutoencoderTemporalSequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving synthetic population from cached file.\n"
     ]
    }
   ],
   "source": [
    "from data.synthetic.SyntheticMeshPopulation import SyntheticMeshPopulation\n",
    "from data.SyntheticDataModules import SyntheticMeshesDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.helpers import get_datamodule, get_coma_args\n",
    "\n",
    "config = load_yaml_config(\"../config_files/config_folded_c_and_s.yaml\")\n",
    "dm = get_datamodule(config)\n",
    "coma_args = get_coma_args(config, dm)\n",
    "coma_args[\"phase_input\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `EncoderTemporalSequence`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Status: tested and working*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_config = {k: v for k,v in coma_args.items() if k in Model4D.ENCODER_ARGS}\n",
    "cine_encoder = EncoderTemporalSequence(enc_config, z_aggr_function=\"DFT\", n_timeframes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the model on a single datapoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 20, 1002, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoint = next(iter(dm.train_dataloader()))\n",
    "s_t = datapoint[\"s_t\"]\n",
    "s_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = cine_encoder(s_t)[\"mu\"]\n",
    "mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DecoderStyle`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Status: tested and working*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_c_config = {k: v for k,v in coma_args.items() if k in Model4D.DECODER_C_ARGS}\n",
    "dec_s_config = {k: v for k,v in coma_args.items() if k in Model4D.DECODER_S_ARGS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_s = DecoderStyle(dec_s_config, phase_embedding_method=\"exp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "zc_dim = dec_s_config[\"latent_dim_content\"]\n",
    "zs_dim = dec_s_config[\"latent_dim_style\"]\n",
    "zc = Tensor(np.random.random((config.batch_size, zc_dim)))\n",
    "zs = Tensor(np.random.random((config.batch_size, zs_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_hat = decoder_s(zc, zs, coma_args[\"n_timeframes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DecoderTemporalSequence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_4d = DecoderTemporalSequence(dec_c_config, dec_s_config, phase_embedding_method=\"exp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `AutoencoderTemporalSequence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_config = [enc_config, dec_c_config, dec_s_config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_4d = AutoencoderTemporalSequence(*ae_config, z_aggr_function=\"dft\", n_timeframes=coma_args[\"n_timeframes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_shat, shat_t = autoencoder_4d(s_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1002, 3])\n",
      "torch.Size([16, 20, 1002, 3])\n"
     ]
    }
   ],
   "source": [
    "print(avg_shat.shape)\n",
    "print(shat_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Lightning modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.lightning.DecoderLightningModule as decoder_lightning; decoder_lightning = reload(module=decoder_lightning)\n",
    "TemporalDecoderLightning = decoder_lightning.TemporalDecoderLightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_c_config[\"latent_dim_content\"] = 9\n",
    "dec_s_config[\"latent_dim_content\"] = 9\n",
    "dec_s_config[\"latent_dim_style\"] = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_4d = DecoderTemporalSequence(dec_c_config, dec_s_config, phase_embedding_method=\"exp\")\n",
    "dec_pl = TemporalDecoderLightning(decoder_4d, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/rodrigo/anaconda3/envs/cardio/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "\n",
      "  | Name  | Type                    | Params\n",
      "--------------------------------------------------\n",
      "0 | model | DecoderTemporalSequence | 207 K \n",
      "--------------------------------------------------\n",
      "207 K     Trainable params\n",
      "0         Non-trainable params\n",
      "207 K     Total params\n",
      "0.831     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Jupyter Widget\n",
      "Python 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:25:59) \n",
      "Type 'copyright', 'credits' or 'license' for more information\n",
      "IPython 8.2.0 -- An enhanced Interactive Python. Type '?' for help.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "In [1]:  quit()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Python 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:25:59) \n",
      "Type 'copyright', 'credits' or 'license' for more information\n",
      "IPython 8.2.0 -- An enhanced Interactive Python. Type '?' for help.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "In [1]:  quit()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A Jupyter Widget\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/anaconda3/envs/cardio/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:432: UserWarning: The number of training samples (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:25:59) \n",
      "Type 'copyright', 'credits' or 'license' for more information\n",
      "IPython 8.2.0 -- An enhanced Interactive Python. Type '?' for help.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "In [1]:  quit()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/anaconda3/envs/cardio/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/closure.py:35: LightningDeprecationWarning: One of the returned values {'recon_loss_c', 'recon_loss_s'} has a `grad_fn`. We will detach it automatically but this behaviour will change in v1.6. Please detach it manually: `return {'loss': ..., 'something': something.detach()}`\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:25:59) \n",
      "Type 'copyright', 'credits' or 'license' for more information\n",
      "IPython 8.2.0 -- An enhanced Interactive Python. Type '?' for help.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/anaconda3/envs/cardio/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer()\n",
    "trainer.fit(dec_pl, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEncoder = CineComaEncoder(cine_encoder, config)\n",
    "# trainer = pl.Trainer()\n",
    "# trainer.fit(PLEncoder, dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cardio",
   "language": "python",
   "name": "cardio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
